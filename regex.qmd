---
title: "String Manipulation with Regular Expressions"
subtitle: "Parks Canada; Ecological Integrity Monitoring Program"
author: "Andy Teucher"
format: revealjs
knitr:
  opts_chunk: 
    R.options:
      width: 110
      pillar.print_max: 5
      pillar.print_min: 5
    echo: true
---

```{r}
#| include: false
library(stringr)
```

## Why regular expressions?

Working with text data is common in data science:

::: {.incremental}
- **File names**: Extract dates, site IDs, or plot numbers
- **Data cleaning**: Standardize species codes, fix formatting
- **Data validation**: Check if values match expected patterns
:::

::: {.fragment}
**Regular expressions** (regex) are a powerful pattern-matching language for working with text.
:::

## The `stringr` package

Part of the tidyverse, `stringr` makes working with strings consistent and easy.

```{r}
library(stringr)
```

::: {.incremental}
All `stringr` functions:

- Start with `str_`
- Take the string as the first argument (pipe-friendly!)
- Use regular expressions for pattern matching
:::

## Basic string operations

Before regex, let's see simple `stringr` functions:

```{r}
sites <- c(
  "Banff National Park",
  "Jasper National Park",
  "Yoho National Park",
  "Kootenay National Park"
)
```

::: {.fragment}

```{r}
str_length(sites) # Count characters
```

:::
::: {.fragment}

```{r}
str_to_upper(sites) # Convert to uppercase
```

:::
::: {.fragment}

```{r}
str_detect(sites, "Banff") # Does it contain "Banff"?
```

:::

## Literal pattern matching

The simplest regex: match exact text

```{r}
files <- c(
  "2024-08-12_site-1_plot-data.csv",
  "2024-08-12_site-2_plot-data.csv",
  "2024-09-15_site-1_plot-data.csv"
)
```

::: {.fragment}

```{r}
# Which files are from site-1?
str_detect(files, "site-1")
```

:::

::: {.fragment}

```{r}
# Extract just the matching files
site1_files <- str_subset(files, "site-1")
site1_files
```

:::

## The dot (`.`): match any character

`.` matches *any single* character

```{r}
species <- c("PIEN", "PICO", "ABLA", "POTR")

# Match PI followed by any two characters
str_detect(species, "PI..")
```

::: {.fragment}
```{r}
# What does it match?
str_subset(species, "PI..")
```

:::

## Character classes: `[]`

Match **one** of several characters

```{r}
codes <- c("Plot1", "Plot2", "Plot3", "PlotA", "PlotB")
```

::: {.fragment}

```{r}
# Match Plot followed by a digit
str_subset(codes, "Plot[123]")
```

:::
::: {.fragment}

```{r}
# Match Plot followed by a letter
str_subset(codes, "Plot[AB]")
```

:::

## Character ranges

Use `-` inside `[ ]` for ranges:

```{r}
# Match any digit
str_subset(codes, "Plot[0-9]")
```

::: {.fragment}
```{r}
# Match any lowercase letter
str_subset(codes, "Plot[a-z]")
```

:::

::: {.fragment}
```{r}
# Match any letter (upper or lower)
str_subset(codes, "Plot[A-Za-z]")
```

:::

## Negating character classes: `[^ ]`

`^` inside `[ ]` means "NOT these characters"

```{r}
measurements <- c("temp_C", "temp_F", "precip_mm", "wind_kph")

# Match measurements NOT in Celsius
str_subset(measurements, "temp_[^C]")
```

## Quantifiers: how many times?

::: {.columns}
::: {.column width="50%"}

- `?` - 0 or 1 time (optional)
- `*` - 0 or more times
- `+` - 1 or more times
- `{n}` - exactly n times
- `{n,m}` - between n and m times

:::

::: {.column width="50%"}

::: {.fragment}

Quantifiers apply to the preceding element.

- `a+` matches one or more 'a's
- `[0-9]{2}` matches exactly two digits
- `-?` matches an optional hyphen
- `8{3,4}` matches the number `8` repeated 3 or 4 times (i.e., `888` or `8888`)

:::
:::
:::

## Quantifiers in action

```{r}
dates <- c("2024-8-12", "2024-08-12", "2024-8-1", "24-08-12", "20240523")
```

::: {.fragment}

```{r}
# Match 4-digit year 2024 and 1 or 2 digits for month
str_detect(dates, "2024-[0-9]{1,2}-")
```

:::
::: {.fragment}

```{r}
# Match exactly 2 digits for month (more strict)
str_detect(dates, "2024-[0-9]{2}-")
```

:::
::: {.fragment}
```{r}
# Match dates regardless of if they use `-` as a separator
str_detect(dates, "[0-9]{4}-?[0-9]{1,2}-?[0-9]{1,2}")
```

:::

## Anchors: position matters

- `^` - start of string
- `$` - end of string

```{r}
filenames <- c("data.csv", "plot-data.csv", "data-plot.csv")

# Files that START with "data"
str_subset(filenames, "^data")
```

::: {.fragment}

```{r}
# Files that END with ".csv"
str_subset(filenames, "\\.csv$") # \\ escapes the .
```

:::

## Special characters need escaping

Some characters have special meaning: `. * + ? [ ] { } ( ) ^ $ | \`

To match them literally, escape with `\\`:

```{r}
prices <- c("$12.99", "$5.00", "12.99", "free")

# Match prices with dollar sign
str_subset(prices, "\\$")
```

::: {.fragment}

```{r}
# Match prices with decimal point
str_subset(prices, "\\.")
```

:::

## Shorthand character classes

Convenient shortcuts:

- `\\d` - any digit (same as `[0-9]`)
- `\\s` - whitespace (space, tab, newline)
- `\\w` - word character (letter, digit, underscore)

::: {.fragment}
```{r}
site_codes <- c("SITE_001", "SITE 002", "SITE-003")

# Match SITE followed by any character, followed by a digit
str_subset(site_codes, "SITE.\\d+")
```

:::

## Extracting matches: `str_extract()`

Get the actual matching text:

```{r}
data_files <- c("2024-08-12_banff_temp.csv", "2024-09-15_jasper_precip.csv")

# Extract the dates
str_extract(data_files, "\\d{4}-\\d{2}-\\d{2}")
```

::: {.fragment}

```{r}
# Extract the park names
str_extract(data_files, "[a-z]+")
```

:::

## Capturing groups: `( )`

Parentheses create groups you can extract separately:

```{r}
dates <- c("2024-08-12", "2024-09-15", "2023-12-31")

# Extract year, month, day separately
str_match(dates, "(\\d{4})-(\\d{2})-(\\d{2})")
```

::: {.fragment}
First column is the full match, then each group.
:::

<br>

::: {.fragment}

### Use `str_extract()` and specify `group` to just get the months

```{r}
str_extract(dates, "(\\d{4})-(\\d{2})-(\\d{2})", group = 2)
```

:::

## Replacing text: `str_replace()`

```{r}
messy_codes <- c("SITE_001", "SITE-002", "SITE_003", "PLOT_004", "PLOT-005")

# Replace hyphens with underscores
str_replace(messy_codes, "-", "_")
```

::: {.fragment}

```{r}
# Replace "SITE" with "PLOT"
str_replace(messy_codes, "SITE", "PLOT")
```

:::
::: {.fragment}

```{r}
# Combine them with pipes
clean_codes <- str_replace(messy_codes, "-", "_") |>
  str_replace("SITE", "PLOT")
clean_codes
```

:::

## Replace all occurrences: `str_replace_all()`

```{r}
text <- "The quick brown fox jumps over the lazy dog"

# Replace first "the" (case-sensitive)
str_replace(text, "the", "a")
```

::: {.fragment}

```{r}
# Replace all spaces with underscores
str_replace_all(text, " ", "_")
```

:::

## Practical regex workflow

::: {.incremental}
1. **Start simple**: Match literal text first
2. **Test iteratively**: Use `str_detect()` and `str_subset()` to verify
3. **Build complexity**: Add character classes, quantifiers
4. **Extract or replace**: Use `str_extract()` or `str_replace()`
5. **Validate**: Check edge cases
:::

::: {.fragment}
**Pro tip**: Use [regex101.com](https://regex101.com) to test and debug patterns!
:::

## Your turn: Exercise 1 {.exercise}

You have these file names:

```{r}
files <- c(
  "2024-08-12_site1_plot-A_data.csv",
  "2024-08-12_site2_plot-B_data.csv",
  "2024-09-15_site1_plot-C_data.csv",
  "2023-12-31_site3_plot-A_data.csv"
)
```

1. Extract all dates (YYYY-MM-DD format)
2. Find files from site1
3. Extract the plot letter (A, B, or C)

::: {.notes}
Give participants 5 minutes to work on this
:::

## Solution: Exercise 1

```{r}
# 1. Extract dates
str_extract(files, "^\\d{4}-\\d{2}-\\d{2}")

# 2. Find files from site1
str_subset(files, "site1")

# 3. Extract plot letter
str_extract(files, "plot-[A-Z]") |>
  str_extract("[A-Z]$")
```

## Your turn: Exercise 2 {.exercise}

You have messy species codes:

```{r}
species <- c(
  "PIEN (Engelmann Spruce)",
  "PICO   Lodgepole Pine",
  "ABLA - Subalpine Fir",
  "POTR/Trembling Aspen"
)
```

1. Extract just the 4-letter species codes
2. Replace all separators (spaces, -, /, parentheses) with a single space
3. Create clean format: "CODE: Common Name"

Hint: Check out `str_squish()` to remove extra whitespace!

::: {.notes}
Give participants 5-7 minutes for this one
:::

## Solution: Exercise 2

```{r}
# 1. Extract 4-letter codes
str_extract(species, "^[A-Z]{4}")

# 2. Replace separators with space
cleaned <- str_replace_all(species, "[()/-]", " ") |>
  str_squish() # Remove extra whitespace

# 3. Create clean format
codes <- str_extract(cleaned, "^[A-Z]{4}")
names <- str_replace_all(cleaned, "^[A-Z]{4} ", "")
paste0(codes, ": ", names)
```

## Resources

- **`stringr` cheatsheet**: [posit.co/resources/cheatsheets](https://posit.co/resources/cheatsheets/)
- **Interactive testing**: [regex101.com](https://regex101.com)
- **Book chapter**: [R for Data Science - Strings](https://r4ds.hadley.nz/strings)
- **Practice**: [regexone.com](https://regexone.com)

::: {.fragment}
**Remember**: Regular expressions are a skill built through practice. Start simple and build complexity as needed!
:::

## Key takeaways

::: {.incremental}
1. `stringr` functions are consistent and pipe-friendly
2. Start with literal matches, add complexity iteratively
3. Common patterns: `.` (any), `[abc]` (one of), `+/*/?/{}` (quantifiers)
4. Use `\\` to escape (match) special characters
5. Test frequently with `str_detect()` and `str_subset()`
6. Anchors (`^`, `$`) and groups `()` give you control
:::
